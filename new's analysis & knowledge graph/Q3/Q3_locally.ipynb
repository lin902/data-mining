{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in d:\\anaconda\\anaconda\\lib\\site-packages (5.14.1)\n",
      "Requirement already satisfied: pytz in d:\\anaconda\\anaconda\\lib\\site-packages (from neo4j) (2019.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\anaconda\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\anaconda\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\jupter\\KnowledgeGraph-20231125T024044Z-001\\hidy.nodes.company.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#查看文件地址\n",
    "# 文件名\n",
    "filename = 'hidy.nodes.company.csv'\n",
    "\n",
    "# 获取文件的实际路径\n",
    "file_path = os.path.abspath(filename)\n",
    "\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看文件\n",
    "import pandas as pd\n",
    "company_df = pd.read_csv('D:\\jupter\\KnowledgeGraph\\KnowledgeGraph\\hidy.nodes.company.csv')\n",
    "\n",
    "compete_df = pd.read_csv('D:\\jupter\\KnowledgeGraph\\KnowledgeGraph\\hidy.relationships.compete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of        :ID company_name       code   :LABEL\n",
       "0        0         东诚药业  002675.SZ  company\n",
       "1        1         大庆华科  000985.SZ  company\n",
       "2        2         恒辉安防  300952.SZ  company\n",
       "3        3         康跃科技  300391.SZ  company\n",
       "4        4          诚益通  300430.SZ  company\n",
       "...    ...          ...        ...      ...\n",
       "3969  3969         圣诺生物  688117.SH  company\n",
       "3970  3970         牧原股份  002714.SZ  company\n",
       "3971  3971         中航高科  600862.SH  company\n",
       "3972  3972         江丰电子  300666.SZ  company\n",
       "3973  3973          珍宝岛  603567.SH  company\n",
       "\n",
       "[3974 rows x 4 columns]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of     :START_ID  :END_ID    :TYPE             time\n",
       "0        2082     2287  compete   2020/4/9 13:33\n",
       "1        3348      272  compete  2018/10/29 7:16\n",
       "2        1431      707  compete   2021/5/17 8:01\n",
       "3         272      743  compete  2022/1/24 20:25\n",
       "4         743      272  compete  2021/7/21 20:48\n",
       "5         743      615  compete   2022/4/23 8:08\n",
       "6         506     2150  compete    2022/4/1 8:26\n",
       "7        1239      554  compete   2021/3/30 7:37\n",
       "8        3216      743  compete  2021/12/27 1:50\n",
       "9        2045     2698  compete   2022/7/20 8:02\n",
       "10       3631     1784  compete   2021/3/24 0:26\n",
       "11       1760     2653  compete   2021/5/8 10:14\n",
       "12       3921     3564  compete  2021/12/21 2:36\n",
       "13        762     3285  compete  2019/2/26 11:01\n",
       "14       2827     1246  compete   2018/12/4 8:23\n",
       "15       2150       12  compete    2018/5/9 0:00\n",
       "16       3414     2525  compete   2018/1/22 0:00\n",
       "17        743     3413  compete   2018/6/19 0:00\n",
       "18       3872     2013  compete   2018/8/29 0:00\n",
       "19       2377     1600  compete   2018/5/18 0:00\n",
       "20       2168     2226  compete   2018/1/31 0:00\n",
       "21       2007     1995  compete   2018/8/28 0:00\n",
       "22        949     3382  compete    2018/9/5 0:00\n",
       "23       1082      481  compete    2018/7/9 0:00\n",
       "24       2032      189  compete   2018/4/17 0:00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compete_df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编码格式:  utf-8\n",
      "可信度:  0.99\n"
     ]
    }
   ],
   "source": [
    "#查看csv文件编码\n",
    "import chardet\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        encoding = result['encoding']\n",
    "        confidence = result['confidence']\n",
    "    return encoding, confidence\n",
    "\n",
    "# 指定CSV文件的路径\n",
    "csv_file_path = 'D:\\jupter\\KnowledgeGraph\\KnowledgeGraph\\hidy.nodes.company.csv'\n",
    "\n",
    "# 调用函数检测编码格式\n",
    "encoding, confidence = detect_encoding(csv_file_path)\n",
    "\n",
    "# 打印结果\n",
    "print(\"编码格式: \", encoding)\n",
    "print(\"可信度: \", confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "在命令行中进入neo4j的bin文件目录，输入以下命令，在graph2中建立1个节点，6个关系，并在conf配置文件修改默认数据库为graph2\n",
    "neo4j-admin database import full graph2 --nodes=company=E:/neo4j-community-5.14.0-windows/neo4j-community-5.14.0/import/hidy.nodes.company.csv --relationships=compete=E:/neo4j-community-5.14.0-windows/neo4j-community-5.14.0/import/hidy.relationships.compete.csv --relationships=cooperate=E:/neo4j-community-5.14.0-windows/neo4j-community-5.14.0/import/hidy.relationships.cooperate.csv --relationships=dispute=E:/neo4j-community-5.14.0-windows/neo4j-community-5.14.0/import/hidy.relationships.dispute.csv --relationships=invest=E:/neo4j-community-5.14.0-windows/neo4j-community-5.14.0/import/hidy.relationships.invest.csv --relationships=same_industry=E:/neo4j-community-5.14.0-windows/neo4j-community-5.14.0/import/hidy.relationships.same_industry.csv --relationships=supply=E:/neo4j-community-5.14.0-windows/neo4j-community-5.14.0/import/hidy.relationships.supply.csv --trim-strings=true\n",
    "在neo4j的\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: py2neo in d:\\anaconda\\anaconda\\lib\\site-packages (2021.2.4)\n",
      "Requirement already satisfied: certifi in d:\\anaconda\\anaconda\\lib\\site-packages (from py2neo) (2019.11.28)\n",
      "Requirement already satisfied: interchange~=2021.0.4 in d:\\anaconda\\anaconda\\lib\\site-packages (from py2neo) (2021.0.4)\n",
      "Requirement already satisfied: monotonic in d:\\anaconda\\anaconda\\lib\\site-packages (from py2neo) (1.6)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\anaconda\\lib\\site-packages (from py2neo) (20.1)\n",
      "Requirement already satisfied: pansi>=2020.7.3 in d:\\anaconda\\anaconda\\lib\\site-packages (from py2neo) (2020.7.3)\n",
      "Requirement already satisfied: pygments>=2.0.0 in d:\\anaconda\\anaconda\\lib\\site-packages (from py2neo) (2.5.2)\n",
      "Requirement already satisfied: six>=1.15.0 in d:\\anaconda\\anaconda\\lib\\site-packages (from py2neo) (1.16.0)\n",
      "Requirement already satisfied: urllib3 in d:\\anaconda\\anaconda\\lib\\site-packages (from py2neo) (1.25.8)\n",
      "Requirement already satisfied: pytz in d:\\anaconda\\anaconda\\lib\\site-packages (from interchange~=2021.0.4->py2neo) (2019.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\anaconda\\anaconda\\lib\\site-packages (from packaging->py2neo) (2.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\anaconda\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\anaconda\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install py2neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph, Node, Relationship, NodeMatcher, Subgraph\n",
    "from py2neo.matching import RelationshipMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e6247a7e79d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'D:\\jupter\\KnowledgeGraph\\negtive.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'D:\\jupter\\KnowledgeGraph\\positive.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\anaconda\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, engine)\u001b[0m\n\u001b[0;32m    819\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[0mformatting_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatting_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                 \u001b[0mon_demand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_demand\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                 \u001b[0mragged_rows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mragged_rows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             )\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mbk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\lib\\site-packages\\xlrd\\xlsx.py\u001b[0m in \u001b[0;36mopen_workbook_2007_xml\u001b[1;34m(zf, component_names, logfile, verbosity, use_mmap, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[0mx12sheet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX12Sheet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m         \u001b[0mheading\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Sheet %r (sheetx=%d) from %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheetx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m         \u001b[0mx12sheet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzflo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheading\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mzflo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\lib\\site-packages\\xlrd\\xlsx.py\u001b[0m in \u001b[0;36mown_process_stream\u001b[1;34m(self, stream, heading)\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[0mrow_tag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mU_SSML12\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"row\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[0mself_do_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mrow_tag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m                 \u001b[0mself_do_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\lib\\xml\\etree\\ElementTree.py\u001b[0m in \u001b[0;36miterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1222\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpullparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m                 \u001b[1;31m# load event buffer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1224\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1225\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\lib\\zipfile.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    928\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eof\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\lib\\zipfile.py\u001b[0m in \u001b[0;36m_read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1004\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compress_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mZIP_DEFLATED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMIN_READ_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m             self._eof = (self._decompressor.eof or\n\u001b[0;32m   1008\u001b[0m                          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compress_left\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_1 = pd.read_excel(r'D:\\jupter\\KnowledgeGraph\\negtive.xlsx')\n",
    "df_2 = pd.read_excel(r'D:\\jupter\\KnowledgeGraph\\positive.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并两个DataFrame\n",
    "df = pd.concat([df_1, df_2])\n",
    "\n",
    "# 将合并后的DataFrame保存到新的Excel文件\n",
    "df.to_excel(r'D:\\jupter\\KnowledgeGraph\\Task1.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'D:\\jupter\\KnowledgeGraph\\Task1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_example = df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsID</th>\n",
       "      <th>NewsContent</th>\n",
       "      <th>Explicit_Company</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>全景网12月1日讯 以下为今日中国银行外汇牌价          货币名称现汇买入价现钞买入...</td>\n",
       "      <td>中国银行</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421</td>\n",
       "      <td>全景网12月4日讯 以下为今日中国银行外汇牌价                    货币名...</td>\n",
       "      <td>中国银行</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>435</td>\n",
       "      <td>中联重科控股子公司长沙浦沅进出口有限公司日前与印度ABG Heavy Industrie...</td>\n",
       "      <td>中联重科</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>708</td>\n",
       "      <td>全景网12月5日讯 以下为今日中国银行外汇牌价            货币名称现汇买入价现钞...</td>\n",
       "      <td>中国银行</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>787</td>\n",
       "      <td>“玉面书生”张良宾控制西昌电力的时代，终于在法律上宣告彻底结束。  　　今日，西昌电力公...</td>\n",
       "      <td>西昌电力</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NewsID                                        NewsContent Explicit_Company  \\\n",
       "0      66  全景网12月1日讯 以下为今日中国银行外汇牌价          货币名称现汇买入价现钞买入...             中国银行   \n",
       "1     421  全景网12月4日讯 以下为今日中国银行外汇牌价                    货币名...             中国银行   \n",
       "2     435  　　中联重科控股子公司长沙浦沅进出口有限公司日前与印度ABG Heavy Industrie...             中联重科   \n",
       "3     708  全景网12月5日讯 以下为今日中国银行外汇牌价            货币名称现汇买入价现钞...             中国银行   \n",
       "4     787  　　“玉面书生”张良宾控制西昌电力的时代，终于在法律上宣告彻底结束。  　　今日，西昌电力公...             西昌电力   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  83%|█████████████████████████████████████████████▍         | 385969/467426 [1:37:19<22:37, 59.99it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"123456abc@\"))\n",
    "df_t2 = pd.DataFrame(columns=['NewsID', 'NewsContent', 'Explicit_Company', 'label',\n",
    "                              'Implicit_Positive_Company', 'Implicit_Negative_Company'])\n",
    "\n",
    "df_t3_data=[]\n",
    "start_time = time.time()\n",
    "with driver.session() as session:\n",
    "    total_rows = len(df)\n",
    "    for i, row in tqdm(df.iterrows(), total=total_rows, desc=\"Processing rows\"):\n",
    "        explicit_company = row['Explicit_Company']\n",
    "        query = \"\"\"\n",
    "        MATCH (a:company)-[r]->(b:company)\n",
    "        WHERE a.company_name = $explicit_company OR b.company_name = $explicit_company\n",
    "        RETURN \n",
    "            CASE WHEN a.company_name = $explicit_company THEN b.company_name ELSE a.company_name END AS implicit_company,\n",
    "            type(r) AS relationship_type\n",
    "        \"\"\"\n",
    "        result = session.run(query, explicit_company=explicit_company)\n",
    "\n",
    "        implicit_pos = []\n",
    "        implicit_neg = []\n",
    "\n",
    "        found_explicit_company = False\n",
    "\n",
    "        for record in result:\n",
    "            implicit_company = record['implicit_company']\n",
    "            relationship_type = record['relationship_type']\n",
    "\n",
    "            if relationship_type in ['same_industry', 'cooperate', 'invest', 'supply']:\n",
    "                if row['label'] == 1:\n",
    "                    implicit_pos.append(implicit_company)\n",
    "                else:\n",
    "                    implicit_neg.append(implicit_company)\n",
    "            elif relationship_type in ['compete', 'dispute']:\n",
    "                if row['label'] == 1:\n",
    "                    implicit_neg.append(implicit_company)\n",
    "                else:\n",
    "                    implicit_pos.append(implicit_company)\n",
    "\n",
    "            found_explicit_company = True\n",
    "\n",
    "        if found_explicit_company:\n",
    "            new_row = {\n",
    "              'NewsID': row['NewsID'],\n",
    "              'NewsContent': row['NewsContent'],\n",
    "              'Explicit_Company': explicit_company,\n",
    "              'label': row['label'],\n",
    "              'Implicit_Positive_Company': ', '.join(str(value) for value in implicit_pos),\n",
    "              'Implicit_Negative_Company': ', '.join(str(value) for value in implicit_neg)\n",
    "              }\n",
    "            df_t3_data.append(new_row)\n",
    "\n",
    "        # 创建 DataFrame\n",
    "df_t3 = pd.DataFrame(df_t3_data)\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"总计算时间: {total_time}秒\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsID</th>\n",
       "      <th>NewsContent</th>\n",
       "      <th>Explicit_Company</th>\n",
       "      <th>label</th>\n",
       "      <th>Implicit_Positive_Company</th>\n",
       "      <th>Implicit_Negative_Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>全景网12月1日讯 以下为今日中国银行外汇牌价          货币名称现汇买入价现钞买入...</td>\n",
       "      <td>中国银行</td>\n",
       "      <td>0</td>\n",
       "      <td>包钢股份, 中国人保, 民生银行, 泰禾集团, 民生银行, 中信国安, 海通证券, 中金岭南...</td>\n",
       "      <td>耀皮玻璃, 平安银行, 中储股份, 中国电信, 天味食品, 迪普科技, 中国人保, 中国人保...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421</td>\n",
       "      <td>全景网12月4日讯 以下为今日中国银行外汇牌价                    货币名...</td>\n",
       "      <td>中国银行</td>\n",
       "      <td>0</td>\n",
       "      <td>包钢股份, 中国人保, 民生银行, 泰禾集团, 民生银行, 中信国安, 海通证券, 中金岭南...</td>\n",
       "      <td>耀皮玻璃, 平安银行, 中储股份, 中国电信, 天味食品, 迪普科技, 中国人保, 中国人保...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>435</td>\n",
       "      <td>中联重科控股子公司长沙浦沅进出口有限公司日前与印度ABG Heavy Industrie...</td>\n",
       "      <td>中联重科</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>中国广核, 碧水源, 盈峰环境, 盈峰环境, 盈峰环境, 盈峰环境, 美的集团, 上海临港,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>708</td>\n",
       "      <td>全景网12月5日讯 以下为今日中国银行外汇牌价            货币名称现汇买入价现钞...</td>\n",
       "      <td>中国银行</td>\n",
       "      <td>0</td>\n",
       "      <td>包钢股份, 中国人保, 民生银行, 泰禾集团, 民生银行, 中信国安, 海通证券, 中金岭南...</td>\n",
       "      <td>耀皮玻璃, 平安银行, 中储股份, 中国电信, 天味食品, 迪普科技, 中国人保, 中国人保...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NewsID                                        NewsContent Explicit_Company  \\\n",
       "0      66  全景网12月1日讯 以下为今日中国银行外汇牌价          货币名称现汇买入价现钞买入...             中国银行   \n",
       "1     421  全景网12月4日讯 以下为今日中国银行外汇牌价                    货币名...             中国银行   \n",
       "2     435  　　中联重科控股子公司长沙浦沅进出口有限公司日前与印度ABG Heavy Industrie...             中联重科   \n",
       "3     708  全景网12月5日讯 以下为今日中国银行外汇牌价            货币名称现汇买入价现钞...             中国银行   \n",
       "\n",
       "   label                          Implicit_Positive_Company  \\\n",
       "0      0  包钢股份, 中国人保, 民生银行, 泰禾集团, 民生银行, 中信国安, 海通证券, 中金岭南...   \n",
       "1      0  包钢股份, 中国人保, 民生银行, 泰禾集团, 民生银行, 中信国安, 海通证券, 中金岭南...   \n",
       "2      0                                                      \n",
       "3      0  包钢股份, 中国人保, 民生银行, 泰禾集团, 民生银行, 中信国安, 海通证券, 中金岭南...   \n",
       "\n",
       "                           Implicit_Negative_Company  \n",
       "0  耀皮玻璃, 平安银行, 中储股份, 中国电信, 天味食品, 迪普科技, 中国人保, 中国人保...  \n",
       "1  耀皮玻璃, 平安银行, 中储股份, 中国电信, 天味食品, 迪普科技, 中国人保, 中国人保...  \n",
       "2  中国广核, 碧水源, 盈峰环境, 盈峰环境, 盈峰环境, 盈峰环境, 美的集团, 上海临港,...  \n",
       "3  耀皮玻璃, 平安银行, 中储股份, 中国电信, 天味食品, 迪普科技, 中国人保, 中国人保...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsID</th>\n",
       "      <th>NewsContent</th>\n",
       "      <th>Explicit_Company</th>\n",
       "      <th>label</th>\n",
       "      <th>Implicit_Positive_Company</th>\n",
       "      <th>Implicit_Negative_Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>全景网12月1日讯 以下为今日中国银行外汇牌价          货币名称现汇买入价现钞买入...</td>\n",
       "      <td>中国银行</td>\n",
       "      <td>0</td>\n",
       "      <td>包钢股份, 中国人保, 民生银行, 泰禾集团, 民生银行, 中信国安, 海通证券, 中金岭南...</td>\n",
       "      <td>耀皮玻璃, 平安银行, 中储股份, 中国电信, 天味食品, 迪普科技, 中国人保, 中国人保...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421</td>\n",
       "      <td>全景网12月4日讯 以下为今日中国银行外汇牌价                    货币名...</td>\n",
       "      <td>中国银行</td>\n",
       "      <td>0</td>\n",
       "      <td>包钢股份, 中国人保, 民生银行, 泰禾集团, 民生银行, 中信国安, 海通证券, 中金岭南...</td>\n",
       "      <td>耀皮玻璃, 平安银行, 中储股份, 中国电信, 天味食品, 迪普科技, 中国人保, 中国人保...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>435</td>\n",
       "      <td>中联重科控股子公司长沙浦沅进出口有限公司日前与印度ABG Heavy Industrie...</td>\n",
       "      <td>中联重科</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>中国广核, 碧水源, 盈峰环境, 盈峰环境, 盈峰环境, 盈峰环境, 美的集团, 上海临港,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>708</td>\n",
       "      <td>全景网12月5日讯 以下为今日中国银行外汇牌价            货币名称现汇买入价现钞...</td>\n",
       "      <td>中国银行</td>\n",
       "      <td>0</td>\n",
       "      <td>包钢股份, 中国人保, 民生银行, 泰禾集团, 民生银行, 中信国安, 海通证券, 中金岭南...</td>\n",
       "      <td>耀皮玻璃, 平安银行, 中储股份, 中国电信, 天味食品, 迪普科技, 中国人保, 中国人保...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NewsID                                        NewsContent Explicit_Company  \\\n",
       "0     66  全景网12月1日讯 以下为今日中国银行外汇牌价          货币名称现汇买入价现钞买入...             中国银行   \n",
       "1    421  全景网12月4日讯 以下为今日中国银行外汇牌价                    货币名...             中国银行   \n",
       "2    435  　　中联重科控股子公司长沙浦沅进出口有限公司日前与印度ABG Heavy Industrie...             中联重科   \n",
       "3    708  全景网12月5日讯 以下为今日中国银行外汇牌价            货币名称现汇买入价现钞...             中国银行   \n",
       "\n",
       "  label                          Implicit_Positive_Company  \\\n",
       "0     0  包钢股份, 中国人保, 民生银行, 泰禾集团, 民生银行, 中信国安, 海通证券, 中金岭南...   \n",
       "1     0  包钢股份, 中国人保, 民生银行, 泰禾集团, 民生银行, 中信国安, 海通证券, 中金岭南...   \n",
       "2     0                                                      \n",
       "3     0  包钢股份, 中国人保, 民生银行, 泰禾集团, 民生银行, 中信国安, 海通证券, 中金岭南...   \n",
       "\n",
       "                           Implicit_Negative_Company  \n",
       "0  耀皮玻璃, 平安银行, 中储股份, 中国电信, 天味食品, 迪普科技, 中国人保, 中国人保...  \n",
       "1  耀皮玻璃, 平安银行, 中储股份, 中国电信, 天味食品, 迪普科技, 中国人保, 中国人保...  \n",
       "2  中国广核, 碧水源, 盈峰环境, 盈峰环境, 盈峰环境, 盈峰环境, 美的集团, 上海临港,...  \n",
       "3  耀皮玻璃, 平安银行, 中储股份, 中国电信, 天味食品, 迪普科技, 中国人保, 中国人保...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t2.to_excel(r'D:\\jupter\\KnowledgeGraph\\Task2_2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-113d0d74a86b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "company_df = pd.read_csv('D:\\jupter\\KnowledgeGraph\\KnowledgeGraph\\hidy.nodes.company.csv')\n",
    "\n",
    "compete_df = pd.read_csv('D:\\jupter\\KnowledgeGraph\\KnowledgeGraph\\hidy.relationships.compete.csv')\n",
    "cooperate_df = pd.read_csv('D:\\jupter\\KnowledgeGraph\\KnowledgeGraph\\hidy.relationships.cooperate.csv')\n",
    "dispute_df = pd.read_csv('D:\\jupter\\KnowledgeGraph\\KnowledgeGraph\\hidy.relationships.dispute.csv')\n",
    "invest_df = pd.read_csv('D:\\jupter\\KnowledgeGraph\\KnowledgeGraph\\hidy.relationships.invest.csv')\n",
    "same_industry_df = pd.read_csv('D:\\jupter\\KnowledgeGraph\\KnowledgeGraph\\hidy.relationships.same_industry.csv')\n",
    "supply_df = pd.read_csv('D:\\jupter\\KnowledgeGraph\\KnowledgeGraph\\hidy.relationships.supply.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relation = pd.concat([compete_df, cooperate_df,dispute_df,invest_df,same_industry_df,supply_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of        :ID company_name       code   :LABEL\n",
       "0        0         东诚药业  002675.SZ  company\n",
       "1        1         大庆华科  000985.SZ  company\n",
       "2        2         恒辉安防  300952.SZ  company\n",
       "3        3         康跃科技  300391.SZ  company\n",
       "4        4          诚益通  300430.SZ  company\n",
       "...    ...          ...        ...      ...\n",
       "3969  3969         圣诺生物  688117.SH  company\n",
       "3970  3970         牧原股份  002714.SZ  company\n",
       "3971  3971         中航高科  600862.SH  company\n",
       "3972  3972         江丰电子  300666.SZ  company\n",
       "3973  3973          珍宝岛  603567.SH  company\n",
       "\n",
       "[3974 rows x 4 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|██                                                           | 15737/467426 [05:16<2:44:22, 45.80it/s]"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d21a3ab60159>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m                           \u001b[1;34m'label'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                           \u001b[1;34m'Implicit_Positive_Company'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimplicit_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                           'Implicit_Negative_Company': ', '.join(implicit_neg)}, ignore_index=True)\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;31m# 结束计时\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "# 创建空DataFrame\n",
    "df_t3 = pd.DataFrame(columns=['NewsID', 'NewsContent', 'Explicit_Company', 'label',\n",
    "                              'Implicit_Positive_Company', 'Implicit_Negative_Company'])\n",
    "\n",
    "\n",
    "# 创建空列表来存储结果\n",
    "implicit_pos = []\n",
    "implicit_neg = []\n",
    "# 开始计时\n",
    "start_time = time.time()\n",
    "\n",
    "total_rows = len(df)\n",
    "# 遍历 df 中的每一行\n",
    "for index, row in tqdm(df.iterrows(), total=total_rows, desc=\"Processing\"):\n",
    "    explicit_company = row['Explicit_Company']\n",
    "    explicit_company_id = None\n",
    "\n",
    "    # 在 company_df 中查找 explicit_company 对应的 ID\n",
    "    matches = company_df[company_df['company_name'] == explicit_company].reset_index(drop=True)\n",
    "    \n",
    "    if not matches.empty:\n",
    "        explicit_company_id = matches.iloc[0][':ID']\n",
    "\n",
    "        # 在 df_relation 中查找与 explicit_company_id 相关的信息\n",
    "        matches = df_relation[(df_relation[':START_ID'] == explicit_company_id) | (df_relation[':END_ID'] == explicit_company_id)]\n",
    "        for _, match_row in matches.iterrows():\n",
    "            relationship_type = match_row[':TYPE']\n",
    "            \n",
    "\n",
    "            # 根据关系类型和标签进行处理\n",
    "            if relationship_type in ['same_industry', 'cooperate', 'invest', 'supply']:\n",
    "                if row['label'] == 1:\n",
    "                    implicit_pos.append(explicit_company)\n",
    "                else:\n",
    "                    implicit_neg.append(explicit_company)\n",
    "            elif relationship_type in ['compete', 'dispute']:\n",
    "                if row['label'] == 1:\n",
    "                    implicit_neg.append(explicit_company)\n",
    "                else:\n",
    "                    implicit_pos.append(explicit_company)\n",
    "                    \n",
    "        \n",
    "        df_t3 = df_t3.append({'NewsID': row['NewsID'],\n",
    "                          'NewsContent': row['NewsContent'],\n",
    "                          'Explicit_Company': explicit_company,\n",
    "                          'label': row['label'],\n",
    "                          'Implicit_Positive_Company': ', '.join(implicit_pos),\n",
    "                          'Implicit_Negative_Company': ', '.join(implicit_neg)}, ignore_index=True)\n",
    "\n",
    "# 结束计时\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"总计算时间: {total_time}秒\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t3.to_excel(r'D:\\jupter\\KnowledgeGraph\\Task1_3.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
